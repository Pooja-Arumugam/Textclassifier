{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24428d0f-876f-46eb-a9e4-2a720996832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import sklearn \n",
    "import pandas \n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd155b6-eedc-4774-bfc0-98bd5decd2c3",
   "metadata": {},
   "source": [
    "## 1. Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea650072-d2b8-40ee-b9b1-5b8d69544df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#load the dataset \n",
    "df=pd.read_table('SMSSpamCollection', header=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86123da8-3b77-48e8-b46e-b8464d368334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0                                                  1\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4d7321f-0a86-4523-9b2f-16740362af9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       5572 non-null   object\n",
      " 1   1       5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecefe377-554e-41e4-8321-adee3147461c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "classes= df[0]\n",
    "print(classes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b72353c-4f41-476b-af4c-0cfb3db94cda",
   "metadata": {},
   "source": [
    "## 2. Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe1b0c6a-fe6a-4240-b773-c2a7342f3906",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the class labels to binary values , 0=ham, 1=spam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "y=encoder.fit_transform(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a23d0485-0a81-4efb-9588-46d7685c6fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     ham\n",
      "1     ham\n",
      "2    spam\n",
      "3     ham\n",
      "4     ham\n",
      "5    spam\n",
      "6     ham\n",
      "7     ham\n",
      "8    spam\n",
      "9    spam\n",
      "Name: 0, dtype: object\n",
      "[0 0 1 0 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(classes[:10])\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa859c7e-94f0-4726-9444-0687ab11e6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Go until jurong point, crazy.. Available only ...\n",
      "1                        Ok lar... Joking wif u oni...\n",
      "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3    U dun say so early hor... U c already then say...\n",
      "4    Nah I don't think he goes to usf, he lives aro...\n",
      "5    FreeMsg Hey there darling it's been 3 week's n...\n",
      "6    Even my brother is not like to speak with me. ...\n",
      "7    As per your request 'Melle Melle (Oru Minnamin...\n",
      "8    WINNER!! As a valued network customer you have...\n",
      "9    Had your mobile 11 months or more? U R entitle...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Store SMS message data\n",
    "text_messages=df[1]\n",
    "print(text_messages[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4f87a18-3614-4998-8808-cd829186c5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using regular expressions to replace email addresses, urls, phone numbers, other numbers and symobols.\n",
    "# Replace email addresses with 'email'\n",
    "processed = text_messages.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$',\n",
    "                                 'emailaddress')\n",
    "\n",
    "# Replace URLs with 'webaddress'\n",
    "processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
    "                                  'webaddress')\n",
    "\n",
    "# Replace money symbols with 'moneysymb' (£ can by typed with ALT key + 156)\n",
    "processed = processed.str.replace(r'£|\\$', 'moneysymb')\n",
    "    \n",
    "# Replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n",
    "processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n",
    "                                  'phonenumbr')\n",
    "    \n",
    "# Replace numbers with 'numbr'\n",
    "processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "727f4867-54c2-4eb1-8d07-3f6dc5db7d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "\n",
    "# Replace whitespace between terms with a single space\n",
    "processed = processed.str.replace(r'\\s+', ' ')\n",
    "\n",
    "# Remove leading and trailing whitespace\n",
    "processed = processed.str.replace(r'^\\s+|\\s+?$', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a50a8ff-7ef9-4407-863e-e3b6ea41a360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       go until jurong point, crazy.. available only ...\n",
      "1                           ok lar... joking wif u oni...\n",
      "2       free entry in 2 a wkly comp to win fa cup fina...\n",
      "3       u dun say so early hor... u c already then say...\n",
      "4       nah i don't think he goes to usf, he lives aro...\n",
      "                              ...                        \n",
      "5567    this is the 2nd time we have tried 2 contact u...\n",
      "5568                 will ü b going to esplanade fr home?\n",
      "5569    pity, * was in mood for that. so...any other s...\n",
      "5570    the guy did some bitching but i acted like i'd...\n",
      "5571                           rofl. its true to its name\n",
      "Name: 1, Length: 5572, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#change words to lower case\n",
    "processed=processed.str.lower()\n",
    "print(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06e58377-1bfc-4116-8969-095303e80d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stop words from the text messages\n",
    "from nltk.corpus import stopwords\n",
    "stop= set(stopwords.words('english'))\n",
    "processed= processed.apply(lambda x:' '.join(term for term in x.split() if term not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d35e9a3-44dd-46b6-afb4-cf5fee0127cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=nltk.PorterStemmer()\n",
    "processed =processed.apply(lambda x: ''.join(ps.stem(term) for term in x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432413c4-d35b-47ab-86ad-4b09e370a853",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5ecf0f3-05e7-4282-a1a1-08e1dcc160e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e30ad4b1-1566-4fd4-9a44-9644b8b38abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # max_features limits the number of features\n",
    "\n",
    "# Fit and transform the processed text data\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(processed)\n",
    "\n",
    "# Convert the TF-IDF matrix to a dense DataFrame for easy viewing (optional)\n",
    "X_tfidf_dense = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ea9cf9-a980-418f-905c-f0b8de24eeea",
   "metadata": {},
   "source": [
    "## Train the model and test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a4de61d-ab43-44d0-940f-759acd5de2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8986547085201794\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94       966\n",
      "           1       1.00      0.24      0.39       149\n",
      "\n",
      "    accuracy                           0.90      1115\n",
      "   macro avg       0.95      0.62      0.67      1115\n",
      "weighted avg       0.91      0.90      0.87      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3ad5e28-7dcf-4c82-a2c6-e1d0e5c60e35",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m----> 2\u001b[0m     confusion_matrix(labels, prediction),\n\u001b[0;32m      3\u001b[0m     index \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactual\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactual\u001b[39m\u001b[38;5;124m'\u001b[39m], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mham\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspam\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[0;32m      4\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted\u001b[39m\u001b[38;5;124m'\u001b[39m], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mham\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspam\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    confusion_matrix(labels, prediction),\n",
    "    index = [['actual', 'actual'], ['ham', 'spam']],\n",
    "    columns = [['predicted', 'predicted'], ['ham', 'spam']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ab3d3b-70bd-4cd4-bacf-3b9c3a906986",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
